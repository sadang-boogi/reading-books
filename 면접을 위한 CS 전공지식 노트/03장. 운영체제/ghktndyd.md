## 운영체제

**운영체제의 역할**

1. CPU 스케줄링, 프로세스 관리
2. 메모리 관리
3. 디스크 파일 정리
4. I/O 디바이스 관리

**운영체제의 구조**
> 유저프로그램 ➡️ ***GUI*** ➡️ ***시스템콜*** ➡️ ***커널*** ➡️ ***드라이버*** ➡️ 하드웨어
>
>  GUI, 시스템콜, 커널, 드라이버가 운영체제의 범위

**시스템콜**
> - 운영체제가 커널에 접근하기 위한 인터페이스
> - 프로세스나 스레드가 운영체제로 요청시 시스템콜을 거쳐서 요청

---

## 컴퓨터의 요소

- CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러로 이루어짐

**CPU - Central Processing Unit**

- 산술 논리 연산 장치
    - Arithmetic Logic Unit
    - 산술 연산, 논리곱 등 논리 연산을 하는 디지털 회로
- 제어 장치
    - 데이터 처리를 위한 순서 결정
- 레지스터
    - CPU 내에 있는 임시 기억 장치
    - 메모리보다 훨씬 연산이 빠름

- CPU는 또 위 3개의 부품으로 나눠짐

- CPU 역할은 *인터럽트*에 의해 메모리에 저장된 명령어를 실행하는 일꾼 역할

- 커널이 프로그램을 메모리에 올려서 프로세스로 만들면 CPU가 실행해줌

*인터럽트*는 어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것

**CPU에서 연산 순서**

1. 제어 장치가 메모리에 계산할 값을 로드, 동시에 레지스터에도 로드
2. 제어 장치가 레지스터에 있는 값을 계산하라고 산술 논리 연산 장치에게 명령
3. 제어 장치가 레지스터에 있는 계산 값을 메모리로 저장

**DMA 컨트롤러**

- I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
- CPU의 보조 일꾼 느낌

**메모리**

- RAM
- 데이터나 상태, 명령어 등을 기록하는 장치
- CPU가 일꾼이면 메모리는 작업장 (작업장이 크면 많은 일을 동시에 가능, 일꾼이 유능하면 일을 빨리 처리)

**타이머**

- 특정 프로그램에 시간 제한을 거는 장치 (몇 초 안에는 이 작업을 끝내야 한다고 제약을 거는 애)

**디바이스 컨트롤러**

- I/O 디바이스들의 작은 CPU

---

## 메모리

> CPU는 그저 메모리에 올라온 일을 처리하는 것 뿐이야.
>
> -메모리



**메모리 계층**

- 메모리 계층은 메모리를 구성하고 있는 순서라고 보면 된다.

> *레지스터 ➡️ 캐시 ➡️ 메모리 ➡️ 저장 장치*
> 여기서 저장 장치를 '보조 기억 장치' 라고 하기도 하고, 메모리를 '주 기억 장치' 혹은 'RAM' 이라고 하기도 한다.

- **RAM**은 저장 장치로부터 **데이터를 복사해서 임시로 저장하고 필요시에 CPU로 전달**한다.

**캐시**

- 데이터를 미리 복사해 놓는 임시 저장소
- 메모리와 CPU는 속도 차이가 심한데 그 중간에 캐시를 둠으로써 속도 차이를 좀 줄여줌

**캐시 히트 & 캐시 미스**

- 캐시 계층에서 원하는 데이터를 찾았다면 캐시 히트
- 못 찾아서 메모리 계층까지 내려가면 캐시 미스

**🤔: 웹 브라우저의 캐시는 뭔데?**
웹 브라우저의 캐시는 쿠키, 로컬 스토리지, 세션 스토리지로 나눠진다. 보통 인증 관련 사항을 처리할 때 쓴다.

**쿠키**는 만료 기한이 있는 키-값 저장소고, 만료기한은 보통 서버에서 정해서 보내줌
**로컬 스토리지**는 만료 기한이 없는 키-값 저장소 (탭을 닫아도 유지됨)
**세션 스토리지**는 만료 기한이 없는 키-값 저장소 (탭을 닫으면 사라짐)

### 메모리 관리

**가상 메모리**

- 메모리 관리 기법 중 하나로 컴퓨터의 실제 이용 가능 메모리 자원을 추상화해서 사용자들에겐 매우 크게 보이게 만드는 기술
- 이게 물리적 메모리에 접근한다기 보다는 **가상 주소 공간**을 사용하여 메모리에 접근함

1. **가상 주소와 실제 주소**
    - 가상 주소: 프로그램이 실행될 때 참조하는 메모리 주소
    - 실제 주소: 가상 주소가 RAM에 매핑될 때 실제로 사용하는 메모리의 물리적 위치

2. **페이지와 페이지 테이블**

- 가상 메모리는 페이지 단위로 관리되는 게 일반적
    - 여기서 페이지는 메모리를 일정 크기로 나눈 작은 블록
    - 운영체제는 프로그램의 가상 주소 공간을 여러 공간으로 나누고, 각 페이지가 물리 메모리 상 어느 위치에 저장되는지를 관리함
- 페이지 테이블은
    1. 가상 주소를 실제 주소로 매핑하는 정보가 저장된 테이블. 프로세스마다 고유한 페이지 테이블을 갖고 있음
    2. 가상 페이지가 물리 메모리의 어느 페이지에 매핑되었는지가 기록되어 있음

3. **TLB (Tanslation Lookaside Buffer)**

- 가상 주소를 실제 주소로 변환하는 데 쓰이는 캐시 메모리
- 가상 메모리 시스템에서 가상 주소를 실제 주소로 변환할 때 운영체제는 페이지 테이블을 조회해야 한다.
- 이 과정은 좀 오래 걸리는 편인데 이걸 빠르게 해결하려면 최근에 참조한 가상 주소와 실제 주소의 매핑 정보를 TLB에 저장해두면 빠르게 조회가 가능하다.

4. **페이지 폴트**

- 가상 메모리 시스템에서 프로그램이 가상 주소를 참조했을 때, 해당 가상 주소가 실제 메모리에 아직 존재 안할 수도 있다. 이럴 때 **페이지 폴트**가 발생했다고 함
- 즉 페이지 폴트는 아래 조건 때문에 발생할 가능성이 높음
    1. 프로그램이 아직 로드되지 않은 데이터를 참조시
    2. 물리적 메모리가 부족해서 데이터를 스왑 영역에 저장했을 시
- 만약 페이지 폴트가 발생하면 운영체제는 스왑 영역에서 해당 데이터를 메모리로 다시 로드하거나 필요한 페이지를 물리 메모리에 할당하는 작업을 함

5. **스와핑**

- 스왑: 물리적 메모리가 부족할 때 사용하지 않는 메모리 페이지를 하드 디스크의 스왑 공간으로 이동시키는 작업

**스레싱 (Thrashing)**

- 스레싱은 프로세스가 필요한 페이지를 너무 **자주 스와핑하면서 과도한 페이지 폴트가 발생했을 때 전체 시스템 성능이 크게 떨어지는 현상**

- **스레싱 발생 이유는 RAM이 과부하 상태일 때 발생한다. 그렇다면 왜 과부하 상태가 될까?**
    1. 메모리가 부족해서: 실행 중인 프로그램들이 물리적 메모리보다 많은 양의 메모리가 필요할 경우 페이지 교체가 너무 많이 발생함
    2. 과도한 멀티태스킹: 너무 많은 프로세스가 동시 실행될 경우에도 페이지 교체가 자주 발생함
    3. 잘못된 워킹 세트 관리: 프로그램이 실제로 자주 사용되는 메모리 영역을 **워킹세트**라고 하는데 워킹 셋을 제대로 관리 못하면 시스템이 페이지 교체 작업만 하게 됨

**메모리 할당 (Memory Allocation)**

- 운영체제가 프로그램 실행에 필요한 메모리를 할당하거나 해제하는 과정을 일컫는 말

1. **메모리 할당의 기본 개념**

- 프로그램은 실행될 때 **코드, 데이터, 스택, 힙** 영역과 같은 메모리 영역을 필요로 한다.

> - **코드 영역**: 프로그램의 기계어가 저장되는 곳. 프로그램이 시작되면 이 영역이 운영체제에 의해 할당됨
> - **데이터 영역**: 전역 변수와 static 변수가 저장되는 공간, 프로그램의 전체 실행 시간동안은 유지
> - **스택 영역**: 함수 호출시 지역 변수, 매개 변수 등이 저장되는 메모리 공간, 함수 호출시 스택 프레임이 생성되고, 끝나면 스택 프레임이 해제됨
> - **힙 영역**: 프로그램 실행 중 동적으로 메모리를 할당하고, 해제하는 영역 (동적 할당된 메모리는 프로그래머가 직접 관리)

2. **정적 메모리 할당 (Static Memory Allocation)**

- 프로그램이 컴파일될 때 필요한 메모리 공간이 미리 할당되는 방식, 주로 `static` 변수처럼 프로그램이 전체 실행 기간 동안 크기와 위치가 변하지 않는 변수들이 정적으로 할당 (`static`은 '고정된'
  이란 뜻)

3. **동적 메모리 할당 (Dynamic Memory Allocation)**

- 프로그램 실행 중에 필요한 메모리를 운영체제에게 요청하여 할당받는 방식, 힙 영역에서 메모리가 할당되며 프로그램이 끝나기 전 언제든지 할당이나 해제가 된다.
- 일례로 C언어에서 `malloc()`, `calloc()` 같은 함수로 할당하고, `free()`로 해제하는 게 있음

4. **메모리 할당 방식**

- 연속적 메모리 할당과 불연속적 메모리 할당으로 나눠짐

**연속적 메모리 할당**

- 프로세스가 연속된 물리적 메모리 공간을 차지하는 방식
- 메모리 단편화(Fragmentation) 문제가 발생할 수 있음

> 메모리 단편화는 2개로 나눠짐
> **외부 단편화**: 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못 하는 현상
> **내부 단편화**: 메모리 크기가 프로세스가 필요한 메모리보다 커서 공간이 낭비되는 현상

**불연속적 메모리 할당**

- 프로세스가 물리적 메모리의 여러 곳에 분산되어 저장될 수 있는 방식
- 메모리 단편화가 발생하지 않음

> **페이징**: 가상 메모리를 일정 크기의 페이지로 나누고, 각 페이지가 물리적 메모리의 임의의 프레임에 저장될 수 있도록 하는 방식
> **세그멘테이션**: 프로그램의 논리적 구조를 기준으로 메모리를 세그먼트로 나누어 할당하는 방식

**페이지 교체 알고리즘**

- 가상 메모리 시스템에서 물리적 메모리가 부족할 때 현재 메모리에 있는 페이지 중 어느 페이지를 내보내고 새로운 페이지를 불러올지를 결정하는 방법이 **페이지 교체 알고리즘**

1. **OPT 알고리즘**

- 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 방식
- 이론적으론 가장 성능이 좋으나 실제론 구현이 절대 불가능

2. **FIFO 알고리즘**

- 가장 먼저 메모리에 들어온 페이지를 먼저 교체하는 방식
- 방식: 메모리에 들어온 순서대로 에 저장하고, 새로운 페이지가 필요하면 가장 먼저 들어온 페이지를 교체

3. **LRU 알고리즘 (Least Frequently Used)**

- 최근에 가장 오래 사용되지 않은 페이지를 교체하는 방식
- 가장 오랫동안 사용되지 않은 페이지가 앞으로도 사용되지 않을 가능성이 높다는 가정하에 작동
- 방식: 각 페이지에 마지막으로 사용된 시간을 기록하고, 가장 오래 전에 사용된 페이지와 교체

4. **LFU 알고리즘 (Least Recently Used)**

- 참조 횟수가 가장 적은 페이지를 교체하는 방식, 즉 덜 사용된 페이지를 교체한다는 뜻
- 방식: 특정 시점에는 자주 사용됐지만 이후로는 사용되지 않는 페이지가 메모리에 남아있을 때 교체

5. **Second Chance 알고리즘**

- FIFO 개선 방식
- 페이지 교체시, 페이지에게 2차 기회를 주어서 최근에 사용된 페이지가 교체 안 되도록 함
- 방식: 각 페이지에 참조 비트를 두고, 페이지 참조시 이 비트를 1로 설정한다. 그리고 페이지 교체가 필요할 때 FIFO 순서대로 페이지를 확인하고 만약 확인한 페이지가 1인 경우 0으로 설정하고 다음 페이지를
  검사한다. 이때 만약 0이면 그 페이지는 교체

7. **페이지 교체 알고리즘 성능 비교**

- 성능 평가 기준은 페이지 폴트의 수가 얼마나 적은지에 따라서 측정
- 실용적으론 LRU (가장 오랫동안 안 사용된 페이지 교체)
- 하지만 LRU는 자원을 너무 많이 씀
- 때문에 Second Chance를 가장 많이 씀

---

## 프로세스와 스레드

- **프로세스**: 실행 중인 프로그램을 의미
- **쓰레드**: 프로세스 내에서 실제 작업을 수행하는 실행 단위

면접 질문으로 많이 나오는 질문 중 하나

```
Q. 프로세스와 쓰레드의 차이
A.
프로세스는 독립된 메모리 공간과 자원을 할당받는다. 반면에 스레드는 같은 프로세스 내에서 자원을 공유한다. 즉 스레드들은 같은 주소 공간, 파일, 전역 변수 등을 공유하므로 스레드 간 통신이 빠른 것이다.
```

**프로세스와 컴파일 과정**

- 프로세스가 만들어지려면 소스 코드가 컴파일 과정을 거쳐야 한다.

1. **전처리**: 소스 코드에서 주석 제거하고 파일 병합하는 단계
2. **컴파일**: 전처리된 코드를 어셈블리어로 변환하는 단계
3. **어셈블**: 어셈블리어로 변환된 코드를 목적 코드로 변환 (목적 코드는 기계어)
4. **링크**: 목적 코드와 필요한 라이브러리들을 결합하여 실행 가능한 바이너리 파일을 생성하는 단계

**프로세스의 상태**

1. **생성(New)**: 프로세스가 생성 중인 상태, 운영체제가 메모리 공간을 할당하는 등 준비 과정이 일어남
2. **준비(Ready)**: 프로세스가 실행될 준비가 된 상태. CPU만 할당받으면 실행 상태로 바뀌지만 아직 CPU 할당을 못 받은 상태
3. **실행(Running)**: 프로세스가 CPU를 할당받아서 실제로 실행 중인 상태
4. **대기(Waiting)**: 프로세스가 일시 중지됨 상태. 예를 들면 파일을 읽는 작업을 기다릴 때
5. **종료(Terminated)**: 프로세스가 모든 작업을 마친 상태, 운영체제가 메모리와 자원을 회수함

**프로세스의 메모리 구조**

- 프로세스는 여러 영역으로 나눠지고, 각 영역은 특정 데이터를 저장하는 데 사용됨

1. **코드 영역**: 실행할 프로그램의 기계어 코드가 저장되는 영역 (보통은 읽기 전용)
2. **데이터 영역**: 전역 변수와 정적 변수가 저장되는 영역, 프로그램이 살아있으면 얘도 살아있음
3. **힙 영역**: 동적으로 할당된 메모리가 저장되는 영역, 동적으로 증가하거나 감소될 수 있음
4. **스택 영역**: 함수 호출시 생성되는 지역 변수, 매개변수 등이 저장되는 영역, 스택은 함수가 호출될 때마다 프레임이 쌓이고, 함수가 끝나면 해당 프레임이 제거되는 구조

**PCB (Process Control Blcok)**

- 운영체제가 각 프로세스를 관리하기 위해서 유지하는 자료구조
- 프로세스가 생성될 때 같이 생성되고, 사라질 때 같이 사라짐
- PCB는 주요한 정보들을 많이 갖고 있다.
- 예를 들면 프로세스 상태, 프로세스 아이디, 프로세스 카운터, 레지스터 값 등등

**멀티 프로세싱 (Multi Processing)**

- 여러 CPU가 동시에 여러 프로세스를 처리하도록 하는 방식
- 멀티 프로세싱에서는 각 CPU가 독립적으로 프로세스를 병렬로 실행 가능하기에 성능이 좋음

멀티 프로세싱도 2가지로 나눠짐

1. **대칭적 멀티 프로세싱 (SMP)**
    - Symmetric Multi Processing
    - 모든 CPU가 동일한 메모리 공간과 자원을 공유
    - 각 프로세스는 어느 CPU에서든 실행될 수 있음
    - 현대 컴퓨터에서 대부분 사용

2. 비대칭적 멀티 프로세싱 (AMP)
    - Asymmetric Multi Processing
    - 하나의 CPU가 메인, 나머지 CPU는 메인 CPU의 명령에 따라서 움직임
    - 현대에는 잘 안 쓰임

**멀티 쓰레딩 (Multi Threading)**

- 멀티 프로세싱이 프로세스를 병렬로 하는 거였음
- 멀티 스레딩은 하나의 프로세스 내에서 여러 스레드를 병렬로 처리하는 방식
- 예) 웹 요청 처리시 새 프로세스를 생성하는 대신 스레드를 이용하는 웹서버는 성능이 좋음

**프로세스 간 통신 (IPC, Inter-Process Communication)**

- 프로세스는 각각 독립적인 메모리 공간을 가진다고 했기에 프로세스 간 데이터를 주고 받으려면 IPC 방법을 써야 됨

**주요한 IPC 방법**

1. **파이프**: 프로세스 간 데이터를 일방향으로 전송하는 통로
2. **메세지 큐**: 메세지를 저장하는 큐를 통해서 프로세스 간에 데이터를 주고 받음
3. **공유 메모리**: 두 프로세스가 같은 메모리 영역을 공유하며 데이터를 교환
4. **소켓**: 네트워크를 통해서 프로세스 간 통신을 할 때 사용

---

### 공유 자원과 임계 영역

**공유 자원 (Shared Resource)**

- 시스템 안에서 각 프로세스, 스레드가 함께 접근 가능한 **I/O 디바이스, 파일, 데이터** 등의 자원이나 변수

**임계 영역 (Critical Section)**

- 둘 이상의 프로세스나 스레드가 공유 자원에 함께 접근할 때 문제가 발생할 수 있는 코드 영역
- 임계 영역은 일관성 유지를 위해서 **동시에 하나의 프로세스나 하나의 스레드만 접근**해야 함

**경쟁 상태 (Race Condition)**

- 두 개 이상의 프로세스가 같은 공유 자원을 동시에 읽거나 쓰는 상황

예시

```
여러 스레드가 동시에 은행 계좌 잔액을 갱신하는 프로그램을 생각해 봅시다. 스레드 1이 100원을 입금하고, 스레드 2가 200원을 입금하려 할 때, 두 스레드가 동시에 같은 잔액 변수에 접근하면 갱신 순서에 따라 최종 잔액이 달라질 수 있습니다. 만약 스레드 1과 스레드 2가 동일한 시점에 잔액을 읽고 수정하면 100 + 200원이 더해져야 할 잔액이 올바르게 반영되지 않을 수 있습니다.
```

**동기화 (Synchronization)**

- 동기화는 **임계 영역**을 안전하게 사용할 수 있도록 하는 방법, 즉 **경쟁 상태를 방지**하고, 공유 자원의 일관성을 유지하도록 보장하는 매커니즘

**동기화 기법**

1. **뮤텍스 (Mutex)**

- **Mutual Exclusion (상호 배제)** 의 줄임말
- 임계 영역에 하나의 프로세스 또는 하나의 스레드만 들어가도록 하는 방식
- 뮤텍스는 이진 락으로 공유 자원을 사용하려는 프로세스나 스레드가 락을 걸고, 나머지 스레드는 락이 해제될 때까지 기다려야 된다.
- 뮤텍스는 **잠금**과 **해제** 두 가지 상태를 가진다.

2. **세마포어 (Semaphore)**

- 일반화된 뮤텍스
- 즉, 임계 영역에 들어갈 수 있는 스레드의 수를 제어하는 기법
- 세마포어는 `P연산(Wait)`, `V연산(Signal)` **2가지 연산**을 지원한다.
    - P연산은 세마포어의 값을 1 감소 시킨다. 값이 0 이상이면 임계 영역에 접근 가능하다.
    - V 연산은 세마포어 값을 1 증가 시킨다. 다른 스레드가 임계 영역에 접근해도 된다는 신호를 보낸다.
- 세마포어는 **2가지 형태**로 구분된다.
    - **이진 세마포어**는 0과 1의 값만 가진다.
    - **이진 세마포어**는 뮤텍스와 비슷하지만 뮤텍스는 잠금 기반이고, 이진 세마포어는 신호 기반이기에 엄연히 다르다.
    - **카운팅 세마포어**는 여러 스레드가 임계 영역에 접근 가능하도록 하는 세마포어다.

3. **모니터 (Monitor)**

- 모니터는 뮤텍스와 조건 변수를 결합해서 임계 영역을 관리하는 동기화 도구다.
- 모니터는 임계 영역의 접근을 제한하고, 하나의 스레드만 임계 영역에 접근 가능하도록 보장한다.
- 모니터의 자원 접근은 자동 상호 배제된다. 자원이 준비되지 않았다면 스레드는 모니터에서 **대기** 상태, 자원이 준비되면 다른 스레드가 **신호**를 보낸다.

**교착 상태 (Dead Lock)**

- 데드락은 여러 스레드나 프로세스가 서로 자원을 기다리며 **무한 대기 상태**에 빠지는 문제다.

**데드락이 발생하는 원인**

- **a. 상호 배제 (Mutual Exclusion)**: 자원은 동시에 하나의 프로세스만 사용 가능
- **b. 점유 대기 (Hold and Wait)**: 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태
- **c. 비선점 (No Preemption)**: 프로세스가 자원을 강제로 빼앗기지 않고, 자발적으로 해제할 때까지 자원을 보유
- **d. 순환 대기 (Circular Wait)**: 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 기다리는 상태

**데드락을 해결하는 방법**

1. **예방 (Prevention)**: 데드락이 발생하는 조건 중 하나를 제거해서 미리 방지한다.
2. **회피 (Avoidance)**: 자원의 상태를 미리 예측하고, 데드락이 발생할 가능성이 있는 상황을 회피한다. (은행원 알고리즘 사용)
3. **탐지 (Detection) 및 회복 (Recovery)**: 데드락이 발생한다면 이를 탐지하고 해결하는 방식, 주기적으로 시스템 상태를 검사해서 데드락 발생 여부를 파악하고, 특정 프로세스를 강제로 종료하여
   자원을 회수한다.

---

## CPU 스케줄링 알고리즘

CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라서 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당한다.

### 비선점형 방식 (Non-Preemptive)

- 한 번 CPU를 할당받은 프로세스가 **자신의 작업이 끝날 때까지** CPU를 점유한다
- 즉, 프로세스가 스스로 CPU를 포기하는 방식이다.

**특징**

1. CPU를 할당받은 프로세스는 **강제로 중단되지 않음**
2. **자발적인 CPU 포기가 있어야만** 다른 프로세스가 CPU를 할당받음
3. **컨텍스트 스위칭이 없으므로** 오버헤드가 적음

**주요 비선점형 스케줄링 알고리즘**

1. **FCFS (First Come, First Served)**

- 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
- 만약 길게 수행되는 프로세스가 있다면 '준비 큐에서 오래 기다리는 현상'이 발생할 가능성이 있음

2. **SJF (Short Job First)**

- 실행 시간이 가장 짧은 프로세스를 가장 먼저 처리하는 알고리즘
- 긴 시간을 가진 프로세스가 실행되지 않는 현상이 일어나기도 함
- 평균 대기 시간이 가장 짧음

3. **우선순위 기반**

- 우선순위가 가장 높은 프로세스에 CPU를 우선 할당하는 알고리즘

### 선점형 방식 (Preemptive)

- 선점형 스케줄링은 실행 중인 프로세스가 CPU를 사용하던 중에도 **더 중요한 작업이나 우선순위가 높은 프로세스가 도착하면 현재 실행 중인 프로세스를 중단**하고, 중요한 프로세스에게 작업을 할당하는 방식

**특징**

- CPU를 할당받은 프로세스가 실행하다가 **강제로 중단**될 수 있음
- 컨텍스트 스위칭이 자주 발생해서 CPU 자원이 빈번하게 다른 프로세스에게 할당됨
- 프로세스간 공정성(fairness)이 높음

**주요 선점형 스케줄링 알고리즘**

1. **라운드 로빈 (RR, Round Robin)**

- 각 프로세스에게 일정 시간을 할당해주고, 그 시간이 지나면 CPU를 다음 프로세스에게 넘겨주는 방식

2. **SRTF (Shortest Remaining Time First)**

- 실행 시간이 가장 짧게 남은 프로세스에게 CPU를 우선 할당하는 방식
- 실행 중인 프로세스보다 더 짧은 작업이 도착하면 CPU가 선점된다.

3. **우선순위 기반**

- 우선순위가 높은 프로세스가 도착하면 현재 실행 중인 프로세스보다 우선순위가 높을 경우 CPU를 빼앗아 할당한다.

### 비선점형 스케줄링 vs 선점형 스케줄링

## 운영체제

1. CPU 스케줄링, 프로세스 관리
2. 메모리 관리
3. 디스크 파일 정리
4. I/O 디바이스 관리

**운영체제의 구조**
> 유저프로그램 ➡️ ***GUI*** ➡️ ***시스템콜*** ➡️ ***커널*** ➡️ ***드라이버*** ➡️ 하드웨어
>
>  GUI, 시스템콜, 커널, 드라이버가 운영체제의 범위

**시스템콜**

- 운영체제가 커널에 접근하기 위한 인터페이스
- 프로세스나 스레드가 운영체제로 요청시 시스템콜을 거쳐서 요청

---

## 컴퓨터의 요소

- CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러로 이루어짐

**CPU - Central Processing Unit**

- 산술 논리 연산 장치
    - Arithmetic Logic Unit
    - 산술 연산, 논리곱 등 논리 연산을 하는 디지털 회로
- 제어 장치
    - 데이터 처리를 위한 순서 결정
- 레지스터
    - CPU 내에 있는 임시 기억 장치
    - 메모리보다 훨씬 연산이 빠름

- CPU는 또 위 3개의 부품으로 나눠짐

역할은 *인터럽트*에 의해 메모리에 저장된 명령어를 실행하는 일꾼 역할

- 커널이 프로그램을 메모리에 올려서 프로세스로 만들면 CPU가 실행해줌

*인터럽트*는 어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것

**CPU에서 연산 순서**

1. 제어 장치가 메모리에 계산할 값을 로드, 동시에 레지스터에도 로드
2. 제어 장치가 레지스터에 있는 값을 계산하라고 산술 논리 연산 장치에게 명령
3. 제어 장치가 레지스터에 있는 계산 값을 메모리로 저장

**DMA 컨트롤러**

- I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
- CPU의 보조 일꾼 느낌

**메모리**

- RAM
- 데이터나 상태, 명령어 등을 기록하는 장치
- CPU가 일꾼이면 메모리는 작업장 (작업장이 크면 많은 일을 동시에 가능, 일꾼이 유능하면 일을 빨리 처리)

**타이머**

- 특정 프로그램에 시간 제한을 거는 장치 (몇 초 안에는 이 작업을 끝내야 한다고 제약을 거는 애)

**디바이스 컨트롤러**

- I/O 디바이스들의 작은 CPU

---

## 메모리

> CPU는 그저 메모리에 올라온 일을 처리하는 것 뿐이야.

**메모리 계층**

- 메모리 계층은 메모리를 구성하고 있는 순서라고 보면 된다.

> *레지스터 ➡️ 캐시 ➡️ 메모리 ➡️ 저장 장치*
> 여기서 저장 장치를 '보조 기억 장치' 라고 하기도 하고, 메모리를 '주 기억 장치' 혹은 'RAM' 이라고 하기도 한다.

- **RAM**은 저장 장치로부터 **데이터를 복사해서 임시로 저장하고 필요시에 CPU로 전달**한다.

**캐시**

- 데이터를 미리 복사해 놓는 임시 저장소
- 메모리와 CPU는 속도 차이가 심한데 그 중간에 캐시를 둠으로써 속도 차이를 좀 줄여줌

**캐시 히트 & 캐시 미스**

- 캐시 계층에서 원하는 데이터를 찾았다면 캐시 히트
- 못 찾아서 메모리 계층까지 내려가면 캐시 미스

**🤔: 웹 브라우저의 캐시는 뭔데?**
웹 브라우저의 캐시는 쿠키, 로컬 스토리지, 세션 스토리지로 나눠진다. 보통 인증 관련 사항을 처리할 때 쓴다.

**쿠키**는 만료 기한이 있는 키-값 저장소고, 만료기한은 보통 서버에서 정해서 보내줌
**로컬 스토리지**는 만료 기한이 없는 키-값 저장소 (탭을 닫아도 유지됨)
**세션 스토리지**는 만료 기한이 없는 키-값 저장소 (탭을 닫으면 사라짐)

### 메모리 관리

**가상 메모리**

- 메모리 관리 기법 중 하나로 컴퓨터의 실제 이용 가능 메모리 자원을 추상화해서 사용자들에겐 매우 크게 보이게 만드는 기술
- 이게 물리적 메모리에 접근한다기 보다는 **가상 주소 공간**을 사용하여 메모리에 접근함

1. **가상 주소와 실제 주소**
    - 가상 주소: 프로그램이 실행될 때 참조하는 메모리 주소
    - 실제 주소: 가상 주소가 RAM에 매핑될 때 실제로 사용하는 메모리의 물리적 위치

2. **페이지와 페이지 테이블**

- 가상 메모리는 페이지 단위로 관리되는 게 일반적
    - 여기서 페이지는 메모리를 일정 크기로 나눈 작은 블록
    - 운영체제는 프로그램의 가상 주소 공간을 여러 공간으로 나누고, 각 페이지가 물리 메모리 상 어느 위치에 저장되는지를 관리함
- 페이지 테이블은
    1. 가상 주소를 실제 주소로 매핑하는 정보가 저장된 테이블. 프로세스마다 고유한 페이지 테이블을 갖고 있음
    2. 가상 페이지가 물리 메모리의 어느 페이지에 매핑되었는지가 기록되어 있음

3. **TLB (Tanslation Lookaside Buffer)**

- 가상 주소를 실제 주소로 변환하는 데 쓰이는 캐시 메모리
- 가상 메모리 시스템에서 가상 주소를 실제 주소로 변환할 때 운영체제는 페이지 테이블을 조회해야 한다.
- 이 과정은 좀 오래 걸리는 편인데 이걸 빠르게 해결하려면 최근에 참조한 가상 주소와 실제 주소의 매핑 정보를 TLB에 저장해두면 빠르게 조회가 가능하다.

4. **페이지 폴트**

- 가상 메모리 시스템에서 프로그램이 가상 주소를 참조했을 때, 해당 가상 주소가 실제 메모리에 아직 존재 안할 수도 있다. 이럴 때 **페이지 폴트**가 발생했다고 함
- 즉 페이지 폴트는 아래 조건 때문에 발생할 가능성이 높음
    1. 프로그램이 아직 로드되지 않은 데이터를 참조시
    2. 물리적 메모리가 부족해서 데이터를 스왑 영역에 저장했을 시
- 만약 페이지 폴트가 발생하면 운영체제는 스왑 영역에서 해당 데이터를 메모리로 다시 로드하거나 필요한 페이지를 물리 메모리에 할당하는 작업을 함

5. **스와핑**

- 스왑: 물리적 메모리가 부족할 때 사용하지 않는 메모리 페이지를 하드 디스크의 스왑 공간으로 이동시키는 작업

**스레싱 (Thrashing)**

- 스레싱은 프로세스가 필요한 페이지를 너무 **자주 스와핑하면서 과도한 페이지 폴트가 발생했을 때 전체 시스템 성능이 크게 떨어지는 현상**

- **스레싱 발생 이유는 RAM이 과부하 상태일 때 발생한다. 그렇다면 왜 과부하 상태가 될까?**
    1. 메모리가 부족해서: 실행 중인 프로그램들이 물리적 메모리보다 많은 양의 메모리가 필요할 경우 페이지 교체가 너무 많이 발생함
    2. 과도한 멀티태스킹: 너무 많은 프로세스가 동시 실행될 경우에도 페이지 교체가 자주 발생함
    3. 잘못된 워킹 세트 관리: 프로그램이 실제로 자주 사용되는 메모리 영역을 **워킹세트**라고 하는데 워킹 셋을 제대로 관리 못하면 시스템이 페이지 교체 작업만 하게 됨

**메모리 할당 (Memory Allocation)**

- 운영체제가 프로그램 실행에 필요한 메모리를 할당하거나 해제하는 과정을 일컫는 말

1. **메모리 할당의 기본 개념**

- 프로그램은 실행될 때 **코드, 데이터, 스택, 힙** 영역과 같은 메모리 영역을 필요로 한다.

> - **코드 영역**: 프로그램의 기계어가 저장되는 곳. 프로그램이 시작되면 이 영역이 운영체제에 의해 할당됨
> - **데이터 영역**: 전역 변수와 static 변수가 저장되는 공간, 프로그램의 전체 실행 시간동안은 유지
> - **스택 영역**: 함수 호출시 지역 변수, 매개 변수 등이 저장되는 메모리 공간, 함수 호출시 스택 프레임이 생성되고, 끝나면 스택 프레임이 해제됨
> - **힙 영역**: 프로그램 실행 중 동적으로 메모리를 할당하고, 해제하는 영역 (동적 할당된 메모리는 프로그래머가 직접 관리)

2. **정적 메모리 할당 (Static Memory Allocation)**

- 프로그램이 컴파일될 때 필요한 메모리 공간이 미리 할당되는 방식, 주로 `static` 변수처럼 프로그램이 전체 실행 기간 동안 크기와 위치가 변하지 않는 변수들이 정적으로 할당 (`static`은 '고정된'
  이란 뜻)

3. **동적 메모리 할당 (Dynamic Memory Allocation)**

- 프로그램 실행 중에 필요한 메모리를 운영체제에게 요청하여 할당받는 방식, 힙 영역에서 메모리가 할당되며 프로그램이 끝나기 전 언제든지 할당이나 해제가 된다.
- 일례로 C언어에서 `malloc()`, `calloc()` 같은 함수로 할당하고, `free()`로 해제하는 게 있음

4. **메모리 할당 방식**

- 연속적 메모리 할당과 불연속적 메모리 할당으로 나눠짐

**연속적 메모리 할당**

- 프로세스가 연속된 물리적 메모리 공간을 차지하는 방식
- 메모리 단편화(Fragmentation) 문제가 발생할 수 있음

> 메모리 단편화는 2개로 나눠짐
> **외부 단편화**: 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못 하는 현상
> **내부 단편화**: 메모리 크기가 프로세스가 필요한 메모리보다 커서 공간이 낭비되는 현상

**불연속적 메모리 할당**

- 프로세스가 물리적 메모리의 여러 곳에 분산되어 저장될 수 있는 방식
- 메모리 단편화가 발생하지 않음

> **페이징**: 가상 메모리를 일정 크기의 페이지로 나누고, 각 페이지가 물리적 메모리의 임의의 프레임에 저장될 수 있도록 하는 방식
> **세그멘테이션**: 프로그램의 논리적 구조를 기준으로 메모리를 세그먼트로 나누어 할당하는 방식

**페이지 교체 알고리즘**

- 가상 메모리 시스템에서 물리적 메모리가 부족할 때 현재 메모리에 있는 페이지 중 어느 페이지를 내보내고 새로운 페이지를 불러올지를 결정하는 방법이 **페이지 교체 알고리즘**

1. **OPT 알고리즘**

- 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 방식
- 이론적으론 가장 성능이 좋으나 실제론 구현이 절대 불가능

2. **FIFO 알고리즘**

- 가장 먼저 메모리에 들어온 페이지를 먼저 교체하는 방식
- 방식: 메모리에 들어온 순서대로 에 저장하고, 새로운 페이지가 필요하면 가장 먼저 들어온 페이지를 교체

3. **LRU 알고리즘 (Least Frequently Used)**

- 최근에 가장 오래 사용되지 않은 페이지를 교체하는 방식
- 가장 오랫동안 사용되지 않은 페이지가 앞으로도 사용되지 않을 가능성이 높다는 가정하에 작동
- 방식: 각 페이지에 마지막으로 사용된 시간을 기록하고, 가장 오래 전에 사용된 페이지와 교체

4. **LFU 알고리즘 (Least Recently Used)**

- 참조 횟수가 가장 적은 페이지를 교체하는 방식, 즉 덜 사용된 페이지를 교체한다는 뜻
- 방식: 특정 시점에는 자주 사용됐지만 이후로는 사용되지 않는 페이지가 메모리에 남아있을 때 교체

5. **Second Chance 알고리즘**

- FIFO 개선 방식
- 페이지 교체시, 페이지에게 2차 기회를 주어서 최근에 사용된 페이지가 교체 안 되도록 함
- 방식: 각 페이지에 참조 비트를 두고, 페이지 참조시 이 비트를 1로 설정한다. 그리고 페이지 교체가 필요할 때 FIFO 순서대로 페이지를 확인하고 만약 확인한 페이지가 1인 경우 0으로 설정하고 다음 페이지를
  검사한다. 이때 만약 0이면 그 페이지는 교체

7. **페이지 교체 알고리즘 성능 비교**

- 성능 평가 기준은 페이지 폴트의 수가 얼마나 적은지에 따라서 측정
- 실용적으론 LRU (가장 오랫동안 안 사용된 페이지 교체)
- 하지만 LRU는 자원을 너무 많이 씀
- 때문에 Second Chance를 가장 많이 씀

---

## 프로세스와 스레드

- **프로세스**: 실행 중인 프로그램을 의미
- **쓰레드**: 프로세스 내에서 실제 작업을 수행하는 실행 단위

면접 질문으로 많이 나오는 질문 중 하나

```
Q. 프로세스와 쓰레드의 차이
A.
프로세스는 독립된 메모리 공간과 자원을 할당받는다. 반면에 스레드는 같은 프로세스 내에서 자원을 공유한다. 즉 스레드들은 같은 주소 공간, 파일, 전역 변수 등을 공유하므로 스레드 간 통신이 빠른 것이다.
```

**프로세스와 컴파일 과정**

- 프로세스가 만들어지려면 소스 코드가 컴파일 과정을 거쳐야 한다.

1. **전처리**: 소스 코드에서 주석 제거하고 파일 병합하는 단계
2. **컴파일**: 전처리된 코드를 어셈블리어로 변환하는 단계
3. **어셈블**: 어셈블리어로 변환된 코드를 목적 코드로 변환 (목적 코드는 기계어)
4. **링크**: 목적 코드와 필요한 라이브러리들을 결합하여 실행 가능한 바이너리 파일을 생성하는 단계

**프로세스의 상태**

1. **생성(New)**: 프로세스가 생성 중인 상태, 운영체제가 메모리 공간을 할당하는 등 준비 과정이 일어남
2. **준비(Ready)**: 프로세스가 실행될 준비가 된 상태. CPU만 할당받으면 실행 상태로 바뀌지만 아직 CPU 할당을 못 받은 상태
3. **실행(Running)**: 프로세스가 CPU를 할당받아서 실제로 실행 중인 상태
4. **대기(Waiting)**: 프로세스가 일시 중지됨 상태. 예를 들면 파일을 읽는 작업을 기다릴 때
5. **종료(Terminated)**: 프로세스가 모든 작업을 마친 상태, 운영체제가 메모리와 자원을 회수함

**프로세스의 메모리 구조**

- 프로세스는 여러 영역으로 나눠지고, 각 영역은 특정 데이터를 저장하는 데 사용됨

1. **코드 영역**: 실행할 프로그램의 기계어 코드가 저장되는 영역 (보통은 읽기 전용)
2. **데이터 영역**: 전역 변수와 정적 변수가 저장되는 영역, 프로그램이 살아있으면 얘도 살아있음
3. **힙 영역**: 동적으로 할당된 메모리가 저장되는 영역, 동적으로 증가하거나 감소될 수 있음
4. **스택 영역**: 함수 호출시 생성되는 지역 변수, 매개변수 등이 저장되는 영역, 스택은 함수가 호출될 때마다 프레임이 쌓이고, 함수가 끝나면 해당 프레임이 제거되는 구조

**PCB (Process Control Blcok)**

- 운영체제가 각 프로세스를 관리하기 위해서 유지하는 자료구조
- 프로세스가 생성될 때 같이 생성되고, 사라질 때 같이 사라짐
- PCB는 주요한 정보들을 많이 갖고 있다.
- 예를 들면 프로세스 상태, 프로세스 아이디, 프로세스 카운터, 레지스터 값 등등

**멀티 프로세싱 (Multi Processing)**

- 여러 CPU가 동시에 여러 프로세스를 처리하도록 하는 방식
- 멀티 프로세싱에서는 각 CPU가 독립적으로 프로세스를 병렬로 실행 가능하기에 성능이 좋음

멀티 프로세싱도 2가지로 나눠짐

1. **대칭적 멀티 프로세싱 (SMP)**
    - Symmetric Multi Processing
    - 모든 CPU가 동일한 메모리 공간과 자원을 공유
    - 각 프로세스는 어느 CPU에서든 실행될 수 있음
    - 현대 컴퓨터에서 대부분 사용

2. 비대칭적 멀티 프로세싱 (AMP)
    - Asymmetric Multi Processing
    - 하나의 CPU가 메인, 나머지 CPU는 메인 CPU의 명령에 따라서 움직임
    - 현대에는 잘 안 쓰임

**멀티 쓰레딩 (Multi Threading)**

- 멀티 프로세싱이 프로세스를 병렬로 하는 거였음
- 멀티 스레딩은 하나의 프로세스 내에서 여러 스레드를 병렬로 처리하는 방식
- 예) 웹 요청 처리시 새 프로세스를 생성하는 대신 스레드를 이용하는 웹서버는 성능이 좋음

**프로세스 간 통신 (IPC, Inter-Process Communication)**

- 프로세스는 각각 독립적인 메모리 공간을 가진다고 했기에 프로세스 간 데이터를 주고 받으려면 IPC 방법을 써야 됨

**주요한 IPC 방법**

1. **파이프**: 프로세스 간 데이터를 일방향으로 전송하는 통로
2. **메세지 큐**: 메세지를 저장하는 큐를 통해서 프로세스 간에 데이터를 주고 받음
3. **공유 메모리**: 두 프로세스가 같은 메모리 영역을 공유하며 데이터를 교환
4. **소켓**: 네트워크를 통해서 프로세스 간 통신을 할 때 사용

---

### 공유 자원과 임계 영역

**공유 자원 (Shared Resource)**

- 시스템 안에서 각 프로세스, 스레드가 함께 접근 가능한 **I/O 디바이스, 파일, 데이터** 등의 자원이나 변수

**임계 영역 (Critical Section)**

- 둘 이상의 프로세스나 스레드가 공유 자원에 함께 접근할 때 문제가 발생할 수 있는 코드 영역
- 임계 영역은 일관성 유지를 위해서 **동시에 하나의 프로세스나 하나의 스레드만 접근**해야 함

**경쟁 상태 (Race Condition)**

- 두 개 이상의 프로세스가 같은 공유 자원을 동시에 읽거나 쓰는 상황

예시

```
여러 스레드가 동시에 은행 계좌 잔액을 갱신하는 프로그램을 생각해 봅시다. 스레드 1이 100원을 입금하고, 스레드 2가 200원을 입금하려 할 때, 두 스레드가 동시에 같은 잔액 변수에 접근하면 갱신 순서에 따라 최종 잔액이 달라질 수 있습니다. 만약 스레드 1과 스레드 2가 동일한 시점에 잔액을 읽고 수정하면 100 + 200원이 더해져야 할 잔액이 올바르게 반영되지 않을 수 있습니다.
```

**동기화 (Synchronization)**

- 동기화는 **임계 영역**을 안전하게 사용할 수 있도록 하는 방법, 즉 **경쟁 상태를 방지**하고, 공유 자원의 일관성을 유지하도록 보장하는 매커니즘

**동기화 기법**

1. **뮤텍스 (Mutex)**

- **Mutual Exclusion (상호 배제)** 의 줄임말
- 임계 영역에 하나의 프로세스 또는 하나의 스레드만 들어가도록 하는 방식
- 뮤텍스는 이진 락으로 공유 자원을 사용하려는 프로세스나 스레드가 락을 걸고, 나머지 스레드는 락이 해제될 때까지 기다려야 된다.
- 뮤텍스는 **잠금**과 **해제** 두 가지 상태를 가진다.

2. **세마포어 (Semaphore)**

- 일반화된 뮤텍스
- 즉, 임계 영역에 들어갈 수 있는 스레드의 수를 제어하는 기법
- 세마포어는 `P연산(Wait)`, `V연산(Signal)` **2가지 연산**을 지원한다.
    - P연산은 세마포어의 값을 1 감소 시킨다. 값이 0 이상이면 임계 영역에 접근 가능하다.
    - V 연산은 세마포어 값을 1 증가 시킨다. 다른 스레드가 임계 영역에 접근해도 된다는 신호를 보낸다.
- 세마포어는 **2가지 형태**로 구분된다.
    - **이진 세마포어**는 0과 1의 값만 가진다.
    - **이진 세마포어**는 뮤텍스와 비슷하지만 뮤텍스는 잠금 기반이고, 이진 세마포어는 신호 기반이기에 엄연히 다르다.
    - **카운팅 세마포어**는 여러 스레드가 임계 영역에 접근 가능하도록 하는 세마포어다.

3. **모니터 (Monitor)**

- 모니터는 뮤텍스와 조건 변수를 결합해서 임계 영역을 관리하는 동기화 도구다.
- 모니터는 임계 영역의 접근을 제한하고, 하나의 스레드만 임계 영역에 접근 가능하도록 보장한다.
- 모니터의 자원 접근은 자동 상호 배제된다. 자원이 준비되지 않았다면 스레드는 모니터에서 **대기** 상태, 자원이 준비되면 다른 스레드가 **신호**를 보낸다.

**교착 상태 (Dead Lock)**

- 데드락은 여러 스레드나 프로세스가 서로 자원을 기다리며 **무한 대기 상태**에 빠지는 문제다.

**데드락이 발생하는 원인**

- **a. 상호 배제 (Mutual Exclusion)**: 자원은 동시에 하나의 프로세스만 사용 가능
- **b. 점유 대기 (Hold and Wait)**: 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태
- **c. 비선점 (No Preemption)**: 프로세스가 자원을 강제로 빼앗기지 않고, 자발적으로 해제할 때까지 자원을 보유
- **d. 순환 대기 (Circular Wait)**: 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 기다리는 상태

**데드락을 해결하는 방법**

1. **예방 (Prevention)**: 데드락이 발생하는 조건 중 하나를 제거해서 미리 방지한다.
2. **회피 (Avoidance)**: 자원의 상태를 미리 예측하고, 데드락이 발생할 가능성이 있는 상황을 회피한다. (은행원 알고리즘 사용)
3. **탐지 (Detection) 및 회복 (Recovery)**: 데드락이 발생한다면 이를 탐지하고 해결하는 방식, 주기적으로 시스템 상태를 검사해서 데드락 발생 여부를 파악하고, 특정 프로세스를 강제로 종료하여
   자원을 회수한다.

---

## CPU 스케줄링 알고리즘

CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라서 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당한다.

### 비선점형 방식 (Non-Preemptive)

- 한 번 CPU를 할당받은 프로세스가 **자신의 작업이 끝날 때까지** CPU를 점유한다
- 즉, 프로세스가 스스로 CPU를 포기하는 방식이다.

**특징**

1. CPU를 할당받은 프로세스는 **강제로 중단되지 않음**
2. **자발적인 CPU 포기가 있어야만** 다른 프로세스가 CPU를 할당받음
3. **컨텍스트 스위칭이 없으므로** 오버헤드가 적음

**주요 비선점형 스케줄링 알고리즘**

1. **FCFS (First Come, First Served)**

- 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
- 만약 길게 수행되는 프로세스가 있다면 '준비 큐에서 오래 기다리는 현상'이 발생할 가능성이 있음

2. **SJF (Short Job First)**

- 실행 시간이 가장 짧은 프로세스를 가장 먼저 처리하는 알고리즘
- 긴 시간을 가진 프로세스가 실행되지 않는 현상이 일어나기도 함
- 평균 대기 시간이 가장 짧음

3. **우선순위 기반**

- 우선순위가 가장 높은 프로세스에 CPU를 우선 할당하는 알고리즘

### 선점형 방식 (Preemptive)

- 선점형 스케줄링은 실행 중인 프로세스가 CPU를 사용하던 중에도 **더 중요한 작업이나 우선순위가 높은 프로세스가 도착하면 현재 실행 중인 프로세스를 중단**하고, 중요한 프로세스에게 작업을 할당하는 방식

**특징**

- CPU를 할당받은 프로세스가 실행하다가 **강제로 중단**될 수 있음
- 컨텍스트 스위칭이 자주 발생해서 CPU 자원이 빈번하게 다른 프로세스에게 할당됨
- 프로세스간 공정성(fairness)이 높음

**주요 선점형 스케줄링 알고리즘**

1. **라운드 로빈 (RR, Round Robin)**

- 각 프로세스에게 일정 시간을 할당해주고, 그 시간이 지나면 CPU를 다음 프로세스에게 넘겨주는 방식

2. **SRTF (Shortest Remaining Time First)**

- 실행 시간이 가장 짧게 남은 프로세스에게 CPU를 우선 할당하는 방식
- 실행 중인 프로세스보다 더 짧은 작업이 도착하면 CPU가 선점된다.

3. **우선순위 기반**

- 우선순위가 높은 프로세스가 도착하면 현재 실행 중인 프로세스보다 우선순위가 높을 경우 CPU를 빼앗아 할당한다.

### 비선점형 스케줄링 vs 선점형 스케줄링

![선점형 스케줄과 비선점형 스케줄링의 차이.png](image/%EC%84%A0%EC%A0%90%ED%98%95%20%EC%8A%A4%EC%BC%80%EC%A4%84%EA%B3%BC%20%EB%B9%84%EC%84%A0%EC%A0%90%ED%98%95%20%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81%EC%9D%98%20%EC%B0%A8%EC%9D%B4.png)